\part{Quantum mechanics}

\chapter{Quantum Mechanics}

    In this chapter, we will study the mathematical framework necessary to study quantum statistical mechanics.

\section{States}

    In quantum mechanics, a pure state of a quantum particle is represented by a normalised vector in a Hilbert space $\ket{\psi} \in \mathcal H$. An Hilbert space $\mathcal H$ is a vector space on $\mathbb C$, i.e.~in which a linear superposition of is still in the space 
    \begin{equation*}
        \lambda \ket{\psi} + \mu \ket{\phi} \in \mathcal H ~, \quad \forall \ket{\psi}, \ket{\phi} \in \mathcal H ~, \forall \lambda, \mu \in \mathbb C ~, 
    \end{equation*}
    endowed with a scalar product $\braket{\psi}{\phi}$. In particular, via the scalar product, it is possible to associate a norm to the state, which is set to zero by the probability intepretation $||\psi||^2 = \braket{\psi}{\psi} = 1$. In the Schoredinger representation, this means that the wave function is a square-integrable function $\psi(t,\mathbf x) \in L^2(\mathbb R^d)$, the probability intepretation tells us that $|\psi(t, \mathbf x)|$ is the probability density to find the particle in a volume element $d^d x$ at time $t$ and the normalisation condition that the total probability to find the particle in the whole $\mathbb R^d$ is $1$ 
    \begin{equation*}
        \int_{\mathbb R^d} d^d x ~ |\psi(t,x)|^2 = 1 ~.
    \end{equation*}
    However, by the normalisation condition, a state is not associated to a single vector, but a class of equivalence of them, called a ray in the Hilbert space, since two states are physically equivalent if $\ket{\psi'} = \exp(i \varphi) \ket{\psi}$, because their norms are the same.

\subsection{Projectors}

    To remove this ambiguity, we introduce the notion of projection operators or projectors, which uniquely determine a state
    \begin{equation*}
        P_\psi = \frac{\ket{\psi} \bra{\psi}}{\braket{\psi}{\psi}} ~,
    \end{equation*}
    which for normalisation states becomes 
    \begin{equation}\label{proj}
        P_\psi = \ket{\psi} \bra{\psi} ~.
    \end{equation}
    \begin{proof}
        If $\ket{\psi'} = \exp(i \varphi) \ket{\psi}$ and $\bra{\psi'} = \exp(- i \varphi) \bra{\psi}$, we have 
        \begin{equation*}
            P_{\psi'} = \ket{\psi'} \bra{\psi'} = \cancel{\exp(i \varphi)} \ket{\psi} \cancel{\exp(- i \varphi)} \bra{\psi} = \ket{\psi} \bra{\psi} = P_\psi ~.
        \end{equation*}
    \end{proof}

    It projects onto the $1$-dimensional subspace $\mathcal H_\psi = \{\lambda \ket{\psi} \colon \lambda \in \mathbb C\}$ generated by the state $\ket{\psi}$
    \begin{equation*}
        P_\psi \colon \mathcal H \rightarrow \mathcal H_\psi ~.
    \end{equation*}
    \begin{proof}
        In fact, $\forall \ket{\phi} \in \mathcal H$, we decomposed the Hilbert space into the direct orthogonal sum of the subspace spanned by $\mathcal H_{\psi}$ and its orthogonal complement $\mathcal H^\perp$:
        \begin{equation*}
            \ket{\phi} = \alpha \ket{\psi} + \beta \ket{\psi^\perp} ~,
        \end{equation*}
        where $\ket{\psi} \in \mathcal H_\psi$, $\ket{\psi^\perp} \in \mathcal H^\perp$ and $\braket{\psi}{\psi^\perp} = 0$. Therefore, the action of the projector is
        \begin{equation*}
            P_\psi \ket{\phi} = \alpha P_\psi \ket{\psi} + \beta P_\psi \ket{\psi^\perp} = \alpha \ket{\psi} \underbrace{\braket{\psi}{\psi}}_1 + \beta \ket{\psi} \underbrace{\braket{\psi}{\psi^\perp}}_0 = \alpha \ket{\psi} \in \mathcal H_\psi ~.
        \end{equation*}
    \end{proof}
    Moreover, since the projectors is orthogonal, we can define the  projector onto the orthogonal subspace as $P_\psi^\perp = \mathbb I - P_\psi$ such that it satisfies $P_\psi P_\psi^\perp = P_\psi^\perp P_\psi = 0$. This can be generalised for a generic set of orthogonal subspaces. In fact, given an orthonormal basis $\{\ket{e_n}\}$, a projector onto an element of this basis is $P_n = \ket{e_n} \bra{e_n}$ and the orthonormality condition reads as $P_n P_m = P_m P_n = 0$ for $n \neq m$.

    It satisfies the following properties 
    \begin{enumerate}
        \item boundness, i.e. 
            \begin{equation*}
                ||P_\psi|| < \infty~,
            \end{equation*}
        \item hermiticity, i.e. 
            \begin{equation*}
                P_\psi^\dagger = P_\psi ~,
            \end{equation*}
        \item idempotence, i.e. 
            \begin{equation}\label{idem}
                P_\psi^2 = P_\psi ~,
            \end{equation}
        \item positive defined, i.e. $\forall \ket{\phi} \in \mathcal H$
            \begin{equation*}
                \bra{\phi} P_\psi \ket{\phi} \geq 0 ~,
            \end{equation*}
        \item trace equals to $1$, i.e. 
            \begin{equation*}
                \tr P_\psi = 1 ~.
            \end{equation*}
    \end{enumerate}
    Actually, there is a theorem that ensures that an operators such that it satifies these 5 conditions is indeed a projector.
    \begin{proof}
        For the boundness, $\forall \ket{\phi} \in \mathcal H$
        \begin{equation*}
            ||P_\psi \ket{\phi}||^2 = \bra{\phi} P_\psi^\dagger P_\psi \ket{\phi} = \braket{\phi}{\psi} \underbrace{\braket{\psi}{\psi}}_1 \braket{\psi}{\phi} = |\braket{\psi}{\phi}|^2 \leq ||\phi||^1 ~,
        \end{equation*}
        hence 
        \begin{equation*}
            ||P_\psi|| = \frac{||P_\psi \ket{\phi}||}{||\phi||} \leq 1 ~.
        \end{equation*}

        For the hermiticity
        \begin{equation*}
            P_\psi^\dagger = (\ket{\psi} \bra{\psi})^\dagger = \bra{\psi}^\dagger \ket{\psi}^\dagger = \ket{\psi} \bra{\psi} = P_\psi ~.
        \end{equation*}

        For the idempotence
        \begin{equation*}
            P_\psi^2 = (\ket{\psi} \bra{\psi})^2 = \ket{\psi} \underbrace{\braket{\psi}{\psi}}_1 \bra{\psi} = \ket{\psi} \bra{\psi} = P_\psi ~.
        \end{equation*}

        For the positive definedness 
        \begin{equation*}
            \bra{\phi} P_\psi \ket{\phi} = \braket{\phi}{\psi} \braket{\psi}{\phi} = |\braket{\psi}{\phi}|^2 \geq 0 ~.
        \end{equation*}

        For the trace, since it is independent from the choice of the basis, we choose $\ket{\psi} = \ket{\psi_1}$ such that $\braket{\psi}{\psi_n} = \delta_{n,1}$ and 
        \begin{equation*}
            \tr P_\psi = \sum_{n=0}^{\infty} \bra{\psi_n} P_\psi \ket{\psi_n} = \sum_{n=0}^{\infty} \underbrace{\braket{\psi_n}{\psi}}_{\delta_{n,1}} \braket{\psi}{\psi_n} = \sum_{n=0}^{\infty} \underbrace{\delta_{n,1}}_{n=1} \braket{\psi}{\psi_n} = \braket{\psi}{\psi_1} = \braket{\psi_1}{\psi_1} = 1 ~.
        \end{equation*}
    \end{proof}

\subsection{Trace}

    Given an orthonormal basis $\{\ket{e_n}\}_{n=1}^\infty$ of a separable Hilbert space, the trace is defined as 
    \begin{equation*}
        \tr A = \sum_{n=1}^\infty A_{nn} = \sum_{n=1}^\infty \bra{e_n} A \ket{e_n} ~.
    \end{equation*}
    It may happen that this series is not convergent. If it is convergent, the operator $A$ is called a trace-class operator. Furthermore, if it is absolute convergent, the trace is independent on the choice of the basis. Recall that in the finite-dimensional case, the trace of a matrix is always convergent and independent on the choice of the basis.

\section{Observables}

    An observable is a linear hermitian operator $\hat A$ acting on the Hilbert space. We require the self-adjointness because, by the spectral theorem, they are always diagonalisable with a positive spectrum. This means that its eigenvalues are real and it always admit an orthonormal eigenbasis $\{\ket{\psi_n}\}$
    \begin{equation}\label{eigen}
        A \ket{\psi_n} = \lambda_n \ket{\psi_n} ~,
    \end{equation}
    where $\lambda_n \in \mathbb R$. In this way, $\forall \ket{\phi} \in \mathcal H$, we can expand it into the eigenbasis 
    \begin{equation}\label{exp}
        \ket{\phi} = \sum_{n=1}^{\infty} c_n \ket{\psi_n} ~,
    \end{equation}
    where $c_n \in \mathbb C$.

    The eigenprojectors, defined as 
    \begin{equation*}
        P_n = \ket{\psi_n} \bra{\psi_n} ~,
    \end{equation*}
    satisfy the following properties 
    \begin{enumerate}
        \item self-adjointness, i.e.
            \begin{equation*}
                P_n^\dagger = P_n ~,
            \end{equation*}
        \item orthonormality, i.e.
            \begin{equation*}
                P_n P_m = \delta_{nm} P_n ~,
            \end{equation*}
        \item completeness relation, i.e.
            \begin{equation}\label{compl}
                \sum_{n = 0}^{\infty} P_n = \mathbb I~,
            \end{equation}
        \item spectral decomposition, i.e.
            \begin{equation}\label{spec}
                \hat A = \sum_{n=0}^{\infty} \lambda_n P_n ~.
            \end{equation}
    \end{enumerate}

\subsection{Measure}

    Prepare a quantum system in a state $\ket{\psi}$. A measurement of an observable $\hat A$ has outcomes corresponding to its eigenvalues $\lambda_n$ with probability $p_n = |c_n|^2$. Recall that $\lambda_n$ are the coefficients in~\eqref{eigen} and $c_n$ in~\eqref{exp}. Its average value is 
    \begin{equation}\label{avval}
        \av{A} = \bra{\psi} \hat A \ket{\psi} = \sum_{n} \lambda_n |c_n|^2 = \sum_{n} \lambda_n p_n ~,
    \end{equation}
    whereas its standard deviation is 
    \begin{equation*}
        (\Delta A)^2 = \av{A^2} - \av{A}^2 ~.
    \end{equation*}
    \begin{proof}
        In fact, using~\eqref{eigen} and~\eqref{exp}
        \begin{equation*}
        \begin{aligned}
            \av{A} & = \bra{\psi} \hat A \ket{\psi} \\ & = \sum_{m=0}^{\infty} c_m^* \bra{\psi_m} \sum_{n=0}^{\infty} c_n \underbrace{\hat A \ket{\psi_n}}_{\lambda_n \ket{\psi_n}} \\ & = \sum_{n=0}^{\infty} \sum_{m=0}^{\infty} \lambda_n c^*_m c^n \underbrace{\braket{\psi_m}{\psi_n}}_{\delta_{nm}} \\ & = \sum_{n=0}^{\infty} \sum_{m=0}^{\infty} \lambda_n c^*_m c^n \underbrace{\delta_{nm}}_{n=m} \\ & = \sum_{n=0}^{\infty} \lambda_n \underbrace{c^*_n c_n}_{|c_n|^2} \\ & = \sum_{n} \lambda_n |c_n|^2 ~.
        \end{aligned}
        \end{equation*}
    \end{proof}

    Notice that measurement in quantum mechanics is a destructive process, since the wave function collapses into one of the eigenstates.

\subsection{Time evolution}

    Time evolution of a quantum system is governed by a special observable, the hamiltonian $\hat H$, through the Schroedinger equation
    \begin{equation*}
        i \hbar \pdv{}{t} \ket{\psi(t)} = \hat H \ket{\psi(t)} ~.
    \end{equation*}
    Notice that this equation is linear, consistent with the superposition principle. It is also at first-order in time, meaning that once the initial condition is fixed, $\ket{\psi(t)}$ is completely determined.
    
    Moreover, for a time-independent hamiltonian, time evolution can be equivalently expressed by a unitary operator $\hat U(t)$  
    \begin{equation}\label{tev}
        \ket{\psi(t)} = \hat U(t) \ket{\psi(0)} ~,
    \end{equation}
    where $\hat U(t) = \exp (\frac{i}{\hbar} \hat H t)$. Since it is unitary 
    \begin{equation*}
        \hat U^\dagger (t) = \exp(- \frac{i}{\hbar} \hat H t) = \hat U(-t) = U^{-1} (t) ~,
    \end{equation*}
    it preserves the probability.

\section{Density matrices and mixed states}

    The projector~\eqref{proj} is also called a density matrix $\rho_\psi$. In terms of the density matrix, the average value~\eqref{avval} of an operator $\hat A$ is 
    \begin{equation*}
        \av{A} = \bra{\psi} \hat A \ket{\psi} = \tr (\hat A \rho_\psi) ~.
    \end{equation*}
    \begin{proof}
        In fact, using~\eqref{compl}
        \begin{equation*}
        \begin{aligned}
            \av{A} & = \bra{\psi} \hat A \ket{\psi} \\ & = \bra{\psi} \mathbb I \hat A \ket{\psi} \\ & = \sum_{n=0}^{\infty} \bra{\psi} P_n \hat A \ket{\psi} \\ & = \sum_{n=0}^{\infty} \braket{\psi}{\psi_n} \bra{\psi_n} \hat A \ket{\psi} \\ & = \sum_{n=0}^{\infty} \bra{\psi_n} \hat A \underbrace{\ket{\psi} \bra{\psi}}_{\rho_\psi} \ket{\psi_n} \\ & = \sum_{n=0}^{\infty} \bra{\psi_n} \hat A \rho_\psi \ket{\psi_n} \\ & = \tr (\hat A \rho_\psi) ~,
        \end{aligned}
        \end{equation*}
        where we have exchanged brakets because they are only numbers.
    \end{proof}

    The time evolution of the density matrix is 
    \begin{equation*}
        \rho_\psi (t) = \exp(- \frac{i}{\hbar} \hat H t) \rho_\psi (0) \exp(\frac{i}{\hbar} \hat H t) ~.
    \end{equation*}
    \begin{proof}
        In fact, using~\eqref{tev}
        \begin{equation*}
            \rho_\psi (t) = \ket{\psi(t)} \bra{\psi(t)} = \exp(- \frac{i}{\hbar} \hat H t) \underbrace{\ket{\psi(0)} \bra{\psi(0)}}_{\rho_\psi (0)} \exp(\frac{i}{\hbar} \hat H t) = \exp(- \frac{i}{\hbar} \hat H t) \rho_\psi (0) \exp(\frac{i}{\hbar} \hat H t) ~.
        \end{equation*}
    \end{proof}

\subsection{Mixed states}

    A mixed state belonging to a classical mixture is a system which can be found in a state $\ket{\psi_n}$ with a probability $p_n$
    \begin{equation*}
        \{\ket{\psi_n}, p_n\} ~,
    \end{equation*}
    where $p_n \geq 0$ and $\sum_{n=0}^{\infty} p_n = 1$. The difference from a pure state is that, in a mixed state, the system is in a classical fixed state before the measurement whereas in a pure state, the state is in a quantum superposition. The density matrix of a mixed state is 
    \begin{equation}\label{mix}
        \rho = \sum_n p_k \ket{\psi_n} \bra{\psi_n} = \sum_n p_n \rho_n ~,
    \end{equation}
    It defines a statistical ensemble. 

    Similarly to the pure state case, it satisfies the following properties
    \begin{enumerate}
        \item boundness, i.e. 
            \begin{equation*}
                ||\rho|| < \infty~,
            \end{equation*}
        \item hermiticity, i.e. 
            \begin{equation*}
                \rho^\dagger = \rho ~,
            \end{equation*}
        \item positive defined, i.e. $\forall \ket{\phi} \in \mathcal H$
            \begin{equation*}
                \bra{\phi} \rho \ket{\phi} \geq 0 ~,
            \end{equation*}
        \item trace equals to $1$, i.e. 
            \begin{equation*}
                \tr \rho = 1 ~.
            \end{equation*}
    \end{enumerate}
    However, the idempotence property~\eqref{idem} is a particular property of only pure states. There is a theorem that states that a state is pure if and only if $\rho^2 = \rho$.
    \begin{proof}
        In the simple case of orthogonal states $\ket{\psi_n}$, i.e. $\braket{\psi_n}{\psi_m} = \delta_{nm}$, we have 
        \begin{equation*}
        \begin{aligned}
            \rho^2 & = \sum_n p_n \ket{\psi_n} \bra{\psi_n} \sum_m p_m \ket{\psi_m} \bra{\psi_m} \\ & = \sum_n \sum_m p_n p_m \ket{\psi_n} \underbrace{\braket{\psi_n}{\psi_m}}_{\delta_{nm}} \bra{\psi_m} \\ & = \sum_n \sum_m p_n p_m \ket{\psi_n} \underbrace{\delta_{nm}}_{n=m} \bra{\psi_m} \\ & = \sum_n p^2_n \ket{\psi_n} \bra{\psi_n} \\ & = \sum_n p^n_n \rho_n ~.
        \end{aligned}
        \end{equation*}
        This means that if $\rho^2 = \rho$, we obtain 
        \begin{equation*}
            p_n^2 = p_n ~,
        \end{equation*}
        which means that $p_{\overline n} = 1$ for a single $\overline n$ and for all the others $p_n = 0$ for $n \neq \overline n$, but this is indeed a pure state $\rho = \ket{\psi_{\overline n}} \bra{\psi_{\overline n}}$.
    \end{proof}

    However, the average value of an observable is the same as the pure states 
    \begin{equation}\label{avobs}
        \av{\hat A} = \bra{\psi} \hat A \ket{\psi} = \tr (\rho \hat A) ~.
    \end{equation}
    \begin{proof}
        In fact, 
        \begin{equation*}
            \av{\hat A} = \sum_n p_n \av{\hat A}_n = \sum_n p_n \tr(\hat A \rho_n) = \tr (\hat A \underbrace{\sum_n p_n \rho_n}_\rho) = \tr (\hat \rho) ~,
        \end{equation*}
        where we have used the linearity of the trace.
    \end{proof}

    Notice that in the classical case, the average value of an observable is~\eqref{clav}
    \begin{equation*}
        \av{f} = \int_{\mathcal M} d^d x ~ f(x) \rho(x) ~,
    \end{equation*}
    which shows that, in the quantum case, we have substituted the integral with the trace, the function with the observable operator and the density distribution with the density matrix.

\section{Composite systems}

    Consider a quantum system composed by $2$ particles. The total Hilbert space is the tensor product between the $2$ single particle Hilbert spaces 
    \begin{equation*}
        \mathcal H_{tot} = \mathcal H_1 \otimes \mathcal H_2 ~. 
    \end{equation*}

    Given an orthonormal basis for each Hilbert space $\{\ket{\psi_n}\} \in \mathcal H_1$ and $\{\ket{\phi_m}\} \in \mathcal H_2$, the orthonormal basis for the total Hilbert space is 
    \begin{equation*}
        \{\ket{\psi_n}_1 \ket{\phi_m}_2 = \ket{\psi_n \phi_m}\} ~,
    \end{equation*}
    such that a generic state can be expanded into this basis, $\forall \ket{\phi} \in \mathcal H_{tot}$
    \begin{equation*}
        \ket{\phi} = \sum_n \sum_m \alpha_{nm} \ket{\psi_n \phi_m} ~,
    \end{equation*}
    where $\alpha_{nm} \in \mathbb C$ and the normalisation condition reads $\sum_{nm} |\alpha_{nm}|^2 = 1$. 

    If the $2$ particle are identical, we have $\mathcal H_1 = \mathcal H_2 = \mathcal H$. Therefore $\mathcal H_{tot} = \mathcal H^{\otimes 2}$.

    The scalar product between two sparable is 
    \begin{equation*}
        \braket{\psi_n \phi_m}{\psi_{n'} \phi_{m'}} = \braket{\psi_n}{\psi_{n'}}_1 \braket{\phi_m}{\phi_{m'}}_2 ~,
    \end{equation*}
    such that if the two states are orthonormal we have
    \begin{equation*}
        \braket{\psi_n \phi_m}{\psi_{n'} \phi_{m'}} = \braket{\psi_n}{\psi_{n'}}_1 \braket{\phi_m}{\phi_{m'}}_2 = \delta_{nn'} \delta_{mm'} ~. 
    \end{equation*}
    
    By linerity, we can generalised this construction for $N$ particles. However, for infinite dimensional Hilbert spaces, we need the convergence of $\sum_{nm} |\alpha_{nm}|^2$ in order to remain in a Hilbert space. The total Hilbert space is 
    \begin{equation*}
        \mathcal H_{tot} = \mathcal H_1 \otimes \ldots \otimes \mathcal H_N ~,
    \end{equation*}
    its orthonormal basis is 
    \begin{equation*}
        \ket{e_{n_1}} \ldots \ket{e_{n_N}} 
    \end{equation*}
    and its scalar product is 
    \begin{equation*}
        \braket{\cdot}{\cdot} = \prod_k \braket{\cdot}{\cdot}_k ~.
    \end{equation*}

    A generic state can be expanded into the orthonormal basis, $\forall \ket{\phi} \in \mathcal H_{tot}$ 
    \begin{equation*}
        \ket{\phi} = \sum_{n_1, \ldots n_N} \alpha_{n_1, \ldots n_N} \ket{e_{n_1}} \ldots \ket{e_{n_N}} ~.
    \end{equation*}

    If all the particles are identical, we have $\mathcal H_1 = \ldots = \mathcal H_N = \mathcal H$. Therefore $\mathcal H_{tot} = \mathcal H^{\otimes N}$.

\subsection{$N$ particles}

    Explicitly, a single particle lives in $\mathbb R^3$ and its Hilbert space is $\mathcal H = L^2 (\mathbb R^3) \ni \psi(x)$. The scalar product is 
    \begin{equation*}
        \braket{\psi}{\phi} = \int d^3 x ~ \psi^*(x) \phi(x) ~,
    \end{equation*}
    where the normalisation condition is 
    \begin{equation*}
        ||\psi||^2 = \braket{\psi}{\psi} = \int_{\mathbb R^3} d^3 x ~ |\psi(x)|^2 < \infty ~.
    \end{equation*}

    For $N$ distinguishable particles, the total Hilbert space is $\mathcal H_{tot} = \mathcal H \otimes \ldots \otimes \mathcal H$ and a generic state is $\ket{\psi_{n_1} \ldots \psi_{n_N}}$ where $\ket{\psi_{n_j}}$ is a single particle state. Explicitly, $N$ distinguishable particle live in $\mathbb R^{3N}$ and their Hilbert space is $\mathcal H_N = L^2(\mathbb R^3) \otimes \ldots \otimes L^2(\mathbb R^3) = L^2 (\mathbb R^{3N}) \ni \psi(x_1, \ldots x_N)$. Therefore, an orthonormal basis is $\{u_{\alpha_1 (x_1)} \ldots u_{\alpha_N (x_N)} = u_{\alpha_1 \ldots \alpha_N} (x_1, \ldots x_N)\}$ where $\{u_\alpha (x)\}$ is the single particle orthonormal basis. A generic state can be expanded in this basis as 
    \begin{equation*}
        \psi(x_1, \ldots x_N) = \sum_{\alpha_1 \ldots \alpha_N} c_{\alpha_1 \ldots \alpha_N} u_{\alpha_1 \ldots \alpha_N} (x_1, \ldots x_N) ~.
    \end{equation*}
    
\subsection{Distinguishable and indistinguishable particles}
    
    Choosing $\alpha_1 = a$ and $\alpha_2 = b$ or viceversa, we obtain
    \begin{equation*}
        u_{\alpha_1 = a} (x_1) u_{\alpha_2 = b} (x_2) \neq u_{\alpha_1 = b} (x_1) u_{\alpha_2 = a} (x_2) ~,
    \end{equation*}
    but if the particle are indistinguishable, we have 
    \begin{equation*}
        u_{\alpha_1 = a} (x_1) u_{\alpha_2 = b} (x_2) \propto u_{\alpha_1 = b} (x_1) u_{\alpha_2 = a} (x_2) ~,
    \end{equation*}
    where the proportionality factor is due to the fact that states are the same up to a global phase factor. This means that they are invariant under permutations
    \begin{equation*}\label{perm}
        \psi(P(x_1, \ldots x_N)) = \exp(i \alpha_P) \psi (x_1, \ldots x_N) ~,
    \end{equation*}
    since in this way 
    \begin{equation*}
        |\psi(P(x_1, \ldots x_N))|^2 = |\psi(x_1, \ldots x_N)|^2 ~,
    \end{equation*}
    where $P$ belongs to the permutation group. In the next chapter, we will evaluate the phase factor $\alpha_P$.

\chapter{Permutation group}

\section{Permutation as consecutive transpositions}

    The premutation of $N$ elements form a group $P_N$. The composition of $2$ permutations $PP'$ is defined as the permutation obtained by applying first $P$ and then $P'$. The identity permutation $\mathbb I$ does not change anything and the inverse is the permutation such that $P P^{-1} = \mathbb I$. 
    \begin{example}
        Given $4$ numbers $(1,2,3,4)$, 
        \begin{enumerate}
            \item the identity is 
                \begin{equation*}
                    (1,2,3,4) \xmapsto{\mathbb I} (1,2,3,4) ~,
                \end{equation*}
            \item the inverse of  
                \begin{equation*}
                    (1,2,3,4) \xmapsto{P} (4,2,1,3) ~,
                \end{equation*}
                is 
                \begin{equation*}
                    (1,2,3,4) \xmapsto{P^{-1}} (3,2,4,1) ~,
                \end{equation*}
                since 
                \begin{equation*}
                    (1,2,3,4) \xmapsto{P} (4,3,1,3) \xmapsto{P^{-1}} (1,2,3,4) ~,
                \end{equation*}
        \end{enumerate}
    \end{example}
    
    This group is generated by transposition, since any permutation $P \in P_N$ can be decomposed and written as a consecutive swap of two near elements 
    \begin{equation*}
        \sigma_i \colon (1,2,\ldots, i, i+1, \ldots N) \mapsto (1,2,\ldots, i+1, i, \ldots N) ~,
    \end{equation*}
    in the following way 
    \begin{equation}\label{decomp}
        P = \sigma_{\alpha_1} \ldots \sigma_{\alpha_k} ~.
    \end{equation}
    However, this decomposition is not unique but the number of transposition in its decomposition is always even or odd. Therefore, we can define the sign of a permutation $\forall P \in P_N$
    \begin{equation*}
        \sgn(P) = \begin{cases}
            + 1 & \textnormal{even number of transposition in its decomposition } \\
            - 1 & \textnormal{odd number of transposition in its decomposition } \\
        \end{cases} ~.
    \end{equation*}

    Transpositions follow the properties 
    \begin{enumerate}
        \item if $|i - j| > 2$, which means that they are not next to each other,
        \begin{equation}\label{prop1}
            \sigma_i \sigma_j = \sigma_j \sigma_i ~,
        \end{equation} 
        \item \begin{equation}\label{prop2}
            \sigma_i \sigma_{i+1} \sigma_i = \sigma_{i+1} \sigma_i \sigma_{i+1} ~,
        \end{equation}
        \item \begin{equation}\label{prop3}
            (\sigma_i)^2 = \mathbb I ~.
        \end{equation}
    \end{enumerate}
    \begin{proof}
        A transposition can be pictorially seen in Figure~\ref{fig:trasp}. The proofs can be seen in Figure~\ref{fig:traspij}, Figure~\ref{fig:traspi1} and Figure~\ref{fig:trasp2}.
    \end{proof}

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}
        % Draw vertical lines
        \foreach \x/\label in {1/~~~~1~\ldots, 2.1/i, 2.6/i+1, 3.7/\ldots~N~~~~~} {
            \draw (\x,0) -- (\x,5) node[above] {\label};
        }
    
        
        % Exchange between the i and j lines
        \draw[thick, white] (2.1,2) -- (2.1,3);
        \draw[thick, white] (2.6,2) -- (2.6,3);
        \draw[thick, black] (2.1,2) -- (2.6,3) node[right] {$\sigma_i$} ;
        \draw[thick, black] (2.6,2) -- (2.1,3);
    
        
        % Add numbers below the lines
        \foreach \x/\label in {1/~~~~1~\ldots, 2.1/i+1, 2.6/i, 3.7/\ldots~N~~~~~} {
            \node at (\x,-0.3) {\label};
        }
    
        \end{tikzpicture}
        \caption{A pictorial diagram of a transposition $\sigma_i$}
        \label{fig:trasp}
    \end{figure}
    
    \begin{figure}
        \centering
        \begin{tikzpicture}
        % Draw vertical lines
        \foreach \x/\label in {1/~~~~1~\ldots, 2.1/i, 2.6/i+1, 3.4/j, 3.9/j+1, 5/\ldots~N~~~~~} {
            \draw (\x,0) -- (\x,5) node[above] {\label};
        }
    
        \foreach \x/\label in {7/~~~~1~\ldots, 8.1/i, 8.6/i+1, 9.4/j, 9.9/j+1, 11/\ldots~N~~~~~} {
            \draw (\x,0) -- (\x,5) node[above] {\label};
        }
    
        
        % Exchange between the i and j lines
        \draw[thick, white] (2.1,3) -- (2.1,4);
        \draw[thick, white] (2.6,3) -- (2.6,4);
        \draw[thick, black] (2.1,3) -- (2.6,4) node[right] {$\sigma_i$} ;
        \draw[thick, black] (2.6,3) -- (2.1,4);
        \draw[thick, white] (3.4,1) -- (3.4,2);
        \draw[thick, white] (3.9,1) -- (3.9,2);
        \draw[thick, black] (3.4,1) -- (3.9,2) node[right] {$\sigma_j$};
        \draw[thick, black] (3.9,1) -- (3.4,2);
    
        \draw[thick, white] (8.1,1) -- (8.1,2);
        \draw[thick, white] (8.6,1) -- (8.6,2);
        \draw[thick, black] (8.1,1) -- (8.6,2) node[right] {$\sigma_i$} ;
        \draw[thick, black] (8.6,1) -- (8.1,2);
        \draw[thick, white] (9.4,3) -- (9.4,4);
        \draw[thick, white] (9.9,3) -- (9.9,4);
        \draw[thick, black] (9.4,3) -- (9.9,4) node[right] {$\sigma_j$} ;
        \draw[thick, black] (9.9,3) -- (9.4,4);
        
        % Add numbers below the lines
        \foreach \x/\label in {1/~~~~1~\ldots, 2.1/i+1, 2.6/i, 3.4/j+1, 3.9/j, 5/\ldots~N~~~~~} {
            \node at (\x,-0.3) {\label};
        }
    
        \foreach \x/\label in {7/~~~~1~\ldots, 8.1/i+1, 8.6/i, 9.4/j+1, 9.9/j, 11/\ldots~N~~~~~} {
            \node at (\x,-0.3) {\label};
        }
        \end{tikzpicture}
        \caption{A pictorial diagram of a transposition $\sigma_i \sigma_j$ on the left and $\sigma_j \sigma_i$ on the right, where $|i - j| > 2$}
        \label{fig:traspij}
    \end{figure}
    
    \begin{figure}
        \centering
        \begin{tikzpicture}
        % Draw vertical lines
        \foreach \x/\label in {1/~~~~1~\ldots, 2.1/i, 2.6/i+1, 3.7/\ldots~N~~~~~} {
            \draw (\x,0) -- (\x,5) node[above] {\label};
        }
    
        
        % Exchange between the i and j lines
        \draw[thick, white] (2.1,1) -- (2.1,2);
        \draw[thick, white] (2.6,1) -- (2.6,2);
        \draw[thick, black] (2.1,1) -- (2.6,2) node[right] {$\sigma_i$} ;
        \draw[thick, black] (2.6,1) -- (2.1,2);
    
        \draw[thick, white] (2.1,3) -- (2.1,4);
        \draw[thick, white] (2.6,3) -- (2.6,4);
        \draw[thick, black] (2.1,3) -- (2.6,4) node[right] {$\sigma_i$} ;
        \draw[thick, black] (2.6,3) -- (2.1,4);
    
        
        % Add numbers below the lines
        \foreach \x/\label in {1/~~~~1~\ldots, 2.1/i, 2.6/i+1, 3.7/\ldots~N~~~~~} {
            \node at (\x,-0.3) {\label};
        }
    
        \end{tikzpicture}
        \caption{A pictorial diagram of a transposition $(\sigma_i)^2$}
        \label{fig:trasp2}
    \end{figure}
    
    \begin{figure}
        \centering
        \begin{tikzpicture}
        % Draw vertical lines
        \foreach \x/\label in {1/~~~~1~\ldots, 2.2/i, 3/i+1, 3.7/i+2, 5/\ldots~N~~~~~} {
            \draw (\x,0) -- (\x,7) node[above] {\label};
        }
    
        \foreach \x/\label in {7/~~~~1~\ldots, 8.2/i, 9/i+1, 9.7/i+2, 11/\ldots~N~~~~~} {
            \draw (\x,0) -- (\x,7) node[above] {\label};
        }
    
        
        % Exchange between the i and j lines
        \draw[thick, white] (2.2,5) -- (2.2,6);
        \draw[thick, white] (3,5) -- (3,6);
        \draw[thick, black] (2.2,5) -- (3,6) node[right] {$\sigma_i$} ;
        \draw[thick, black] (3,5) -- (2.2,6);
        \draw[thick, white] (3,3) -- (3,4);
        \draw[thick, white] (3.7,3) -- (3.7,4);
        \draw[thick, black] (3,3) -- (3.7,4) node[right] {$\sigma_{i+1}$};
        \draw[thick, black] (3.7,3) -- (3,4);
        \draw[thick, white] (2.2,1) -- (2.2,2);
        \draw[thick, white] (3,1) -- (3,2);
        \draw[thick, black] (2.2,1) -- (3,2) node[right] {$\sigma_i$} ;
        \draw[thick, black] (3,1) -- (2.2,2);
    
        \draw[thick, white] (8.2,3) -- (8.2,4);
        \draw[thick, white] (9,3) -- (9,4);
        \draw[thick, black] (8.2,3) -- (9,4) node[right] {$\sigma_i$} ;
        \draw[thick, black] (9,3) -- (8.2,4);
        \draw[thick, white] (9,1) -- (9,2);
        \draw[thick, white] (9.7,1) -- (9.7,2);
        \draw[thick, black] (9,1) -- (9.7,2) node[right] {$\sigma_{i+1}$};
        \draw[thick, black] (9.7,1) -- (9,2);
        \draw[thick, white] (9,5) -- (9,6);
        \draw[thick, white] (9.7,5) -- (9.7,6);
        \draw[thick, black] (9,5) -- (9.7,6) node[right] {$\sigma_{i+1}$};
        \draw[thick, black] (9.7,5) -- (9,6);
        
        
        % Add numbers below the lines
        \foreach \x/\label in {1/~~~~1~\ldots, 2.2/i+2, 3/i+1, 3.7/i, 5/\ldots~N~~~~~} {
            \node at (\x,-0.3) {\label};
        }
    
        \foreach \x/\label in {7/~~~~1~\ldots, 8.2/i+2, 9/i+1, 9.7/i, 11/\ldots~N~~~~~} {
            \node at (\x,-0.3) {\label};
        }
        \end{tikzpicture}
        \caption{A pictorial diagram of a transposition $\sigma_i \sigma_{i+1} \sigma_i$ on the left and $\sigma_{i+1} \sigma_i \sigma_{i+1}$ on the right}
        \label{fig:traspi1}
    \end{figure}

\section{Bosons and fermions}

    Hence, we can calculate explicitly~\eqref{perm}, which is 
    \begin{equation}
        \alpha_P = \alpha_1 + \ldots \alpha_N~,
    \end{equation}
    where $\alpha_i$ is the phase factor of a transposition $\sigma_{\alpha_i}$
    \begin{equation*}
        \psi(\sigma_{\alpha_i}(x_1,\ldots x_N)) = \exp(i \alpha_i) \psi (x_1,\ldots x_N) ~.
    \end{equation*}
    \begin{proof}
        In fact, using~\eqref{decomp}
        \begin{equation*}
        \begin{aligned}
        \psi(P(x_1,\ldots x_N)) & = \psi((\sigma_{\alpha_1} \ldots \sigma_{\alpha_N}) (x_1,\ldots x_N)) \\ & = \exp (i \alpha_1) \psi((\sigma_{\alpha_2} \ldots \sigma_{\alpha_N}) ) \\ & ~~ \vdots \\ & = \exp (i \alpha_1) \ldots \exp (i \alpha_N) \psi(x_1,\ldots x_N) \\ & = \exp (i (\alpha_1 + \ldots \alpha_N)) \psi(x_1,\ldots x_N) \\ &  = \exp (i \alpha_P) \psi(x_1,\ldots x_N)~.
        \end{aligned}
        \end{equation*}
    \end{proof}

    Furthermore, there are only two possibilities for $\alpha_P$ 
    \begin{enumerate}
        \item $\alpha_P = 0$ and $\exp(i \alpha_P) = 1$, which correspond respectively to a bosonic totally symmetric wavefunction, i.e.~under $P$
        \begin{equation*}
            \psi(x_1, \ldots x_N) \xmapsto{P} (+ 1) \psi(x_1, \ldots x_N) ~,
        \end{equation*}
        \item $\alpha_P = \pi$ and $\exp(i \alpha_P) = \sgn(P)$, which correspond respectively to a fermionic totally antysymmetric wavefunction, i.e.~under $P$
        \begin{equation*}
            \psi(x_1, \ldots x_N) \xmapsto{P} \sgn(P) \psi(x_1, \ldots x_N) = \begin{cases}
                + \psi(x_1, \ldots x_N) & \textnormal{sign(P) = +1} \\
                - \psi(x_1, \ldots x_N) & \textnormal{sign(P) = - 1} \\
            \end{cases}~.
        \end{equation*}
    \end{enumerate}
    By the spin-statistic theorem, bosons, which have symmetric wavefunctions, are associated to integer spin particles and fermions, which have antisymmetric wavefunctions, are associated to half-integer spin particles.
    \begin{proof}
        Using~\eqref{prop1}
        \begin{equation*}
            \psi(x_1, \ldots x_N) \xmapsto{\sigma_i} \exp(i \alpha_i) \psi(x_1, \ldots x_N)\xmapsto{\sigma_i \sigma_j} \exp(i \alpha_i) \exp(i \alpha_j) \psi(x_1, \ldots x_N) ~,
        \end{equation*}
        \begin{equation*}
            \psi(x_1, \ldots x_N) \xmapsto{\sigma_j} \exp(i \alpha_j) \psi(x_1, \ldots x_N)\xmapsto{\sigma_j \sigma_i} \exp(i \alpha_j) \exp(i \alpha_i) \psi(x_1, \ldots x_N) ~,
        \end{equation*}
        hence 
        \begin{equation*}
            \exp(i \alpha_i) \exp(i \alpha_j) = \exp(i \alpha_j) \exp(i \alpha_i) ~,
        \end{equation*}
        which means that they commute
        \begin{equation}\label{pr1}
            \alpha_i + \alpha_j = \alpha_j +\alpha_i ~.
        \end{equation}

        Using~\eqref{prop2}
        \begin{equation*}
        \begin{aligned}
            \psi(x_1, \ldots x_N) & \xmapsto{\sigma_i} \exp(i \alpha_i) \psi(x_1, \ldots x_N) \\ & \xmapsto{\sigma_i \sigma_{i+1}} \exp(i \alpha_i) \exp(i \alpha_{i+1}) \psi(x_1, \ldots x_N) \\ & \xmapsto{\sigma_i \sigma_{i+1} \sigma_i} \exp(i \alpha_i) \exp(i \alpha_{i+1}) \exp(i \alpha_i) \psi(x_1, \ldots x_N) ~,
        \end{aligned}
        \end{equation*}
        \begin{equation*}
        \begin{aligned}
            \psi(x_1, \ldots x_N) & \xmapsto{\sigma_{i+1}} \exp(i \alpha_{i+1}) \psi(x_1, \ldots x_N) \\ & \xmapsto{\sigma_{i+1} \sigma_i} \exp(i \alpha_{i+1}) \exp(i \alpha_i) \psi(x_1, \ldots x_N) \\ & \xmapsto{\sigma_{i+1} \sigma_i \sigma_{i+1} } \exp(i \alpha_{i+1}) \exp(i \alpha_i) \exp(i \alpha_{i+1}) \psi(x_1, \ldots x_N) ~,
        \end{aligned}
        \end{equation*}
        hence 
        \begin{equation*}
            \exp(i \alpha_i) \exp(i \alpha_{i+1}) \exp(i \alpha_i) = \exp(i \alpha_{i+1}) \exp(i \alpha_i) \exp(i \alpha_{i+1}) ~,
        \end{equation*}
        which means that 
        \begin{equation}\label{pr2}
           \alpha_i + \alpha_{i+1} + \alpha_i = \alpha_{i+1} + \alpha_i + \alpha_{i+1} ~. 
        \end{equation}
        
        Putting together this two properties~\eqref{pr1} and ~\eqref{pr2}, we have
        \begin{equation*}
            \alpha_i + \alpha_{i+1} + \alpha_i = \alpha_{i+1} + \alpha_i + \alpha_{i+1} ~,
        \end{equation*}
        \begin{equation*}
            \cancel{\alpha_{i+1}} + \cancel{\alpha_i }+ \alpha_i = \cancel{\alpha_{i+1}} + \cancel{\alpha_i} + \alpha_{i+1} ~,
        \end{equation*}
        \begin{equation*}
            \alpha_i = \alpha_{i+1} ~.
        \end{equation*}
        Therefore, $\forall i= 1, \ldots N-1$ and $\alpha_i \in [0, 2\pi[$ we have $\alpha_i = \alpha_{i+1} = \alpha$.

        Using~\eqref{prop3}
        \begin{equation*}
            \exp(i \alpha)^2 = \exp (2 i \alpha) = \mathbb I = \exp(0) ~,
        \end{equation*}
        which means that 
        \begin{equation*}
            \alpha = 0, \pi ~.
        \end{equation*}

        Finally, there are only two possibilities 
        \begin{equation*}
            \psi(x_1, \ldots x_N) \xmapsto{\sigma_i} \underbrace{\exp(i 0)}_{+1} \psi(x_1, \ldots x_N) = \psi(x_1, \ldots x_N)
        \end{equation*}
        and 
        \begin{equation*}
            \psi(x_1, \ldots x_N) \xmapsto{\sigma_i} \underbrace{\exp(i \pi)}_{-1} \psi(x_1, \ldots x_N) = - \psi(x_1, \ldots x_N)~.
        \end{equation*}
    \end{proof}

    The Hilbert space of indistinguishable particle is smaller than the distinguishable one, because we have seen that the phase factor can only have two possible values. In the next chapters, we will see how we can describe such spaces, in terms of the symmetrised or antisymmetrised Hilbert space $\mathcal H_{S/A}$ in the language of first quantisation and in terms of the Fock space $\mathcal F_{B/F}$ in the language of second quantisation.

\chapter{First quantisation}

\section{Symmetric/antisymmetric Hilbert space} 

\subsection{$2$ particles}

    Consider $2$ particles. If they are distinguishable, the total Hilbert space is 
    \begin{equation*}
        \mathcal H_{tot} = \mathcal H \otimes \mathcal H ~,
    \end{equation*}
    whereas if the particles are indistinguishable, we can decomposed the Hilbert space into
    \begin{equation*}
        \mathcal H_{tot} = \mathcal H_S \oplus_\perp  \mathcal H_A ~.
    \end{equation*} 
    \begin{proof}
        In fact, given two states $\ket{a}_1 \in \mathcal H_1$ and $\ket{b}_2 \in \mathcal H_2$, we have 
    \begin{equation*}
    \begin{aligned}
        \ket{a}_1\ket{b}_2 & = \frac{2}{2} \ket{a}_1\ket{b}_2 + \frac{1}{2} \ket{b}_1\ket{a}_2 - \frac{1}{2} \ket{b}_1\ket{a}_2 \\ & = \underbrace{\frac{\ket{a}_1\ket{b}_2 + \ket{b}_1\ket{a}_2}{2}}_{\ket{\psi_S}} + \underbrace{\frac{\ket{a}_1\ket{b}_2 - \ket{b}_1\ket{a}_2}{2}}_{\ket{\psi_A}} \\ & = \ket{\psi_S} + \ket{\psi_A} ~.
    \end{aligned}
    \end{equation*}
    Furthermore, the permutation group for $2$ particles is $P_2 = \{\mathbb I, \sigma\}$. The symmetric part $\ket{\psi_S} \in \mathcal H_S$, since
    \begin{equation*}
        \sigma \ket{\psi_S} = \sigma \frac{\ket{a}_1\ket{b}_2 + \ket{b}_1\ket{a}_2}{2} = \frac{\ket{b}_1\ket{a}_2 + \ket{a}_1\ket{b}_2}{2} = \frac{\ket{a}_1\ket{b}_2 + \ket{b}_1\ket{a}_2}{2} = \ket{\psi_S} ~,
    \end{equation*}
    where we used the commutativity property. The antysymmetric part is $\ket{\psi_A} \in \mathcal H_A$, since
    \begin{equation*}
        \sigma \ket{\psi_A} = \sigma \frac{\ket{a}_1\ket{b}_2 - \ket{b}_1\ket{a}_2}{2} = \frac{\ket{b}_1\ket{a}_2 - \ket{a}_1\ket{b}_2}{2} = - \frac{\ket{a}_1\ket{b}_2 - \ket{b}_1\ket{a}_2}{2} = - \ket{\psi_A} ~,
    \end{equation*}
    where we used the commutativity property. Finally, the decomposition is orthogonal, since 
    \begin{equation*}
    \begin{aligned}
        \braket{\psi_S}{\psi_A} & = \frac{\bra{a}_1\bra{b}_2 + \bra{b}_1\bra{a}_2}{2} \frac{\ket{a}_1 \ket{b}_2 - \ket{b}_1 \ket{a}_2}{2} \\ & = \frac{1}{4} (\underbrace{\braket{a}{a}_1}_1 \underbrace{\braket{b}{b}_2}_1 - \braket{a}{b}_1 \braket{b}{a}_2 + \braket{b}{a}_1 \braket{a}{b}_2 - \underbrace{\braket{b}{b}_1}_1 \underbrace{\braket{a}{a}_2}_1) \\ & = \frac{1}{4} (- \braket{a}{b}_1 \braket{b}{a}_2 + \braket{b}{a}_1 \braket{a}{b}_2)  
    \end{aligned}
    \end{equation*}
    and 
    \begin{equation*}
    \begin{aligned}
        - \braket{\psi_S}{\psi_A} & = - \frac{\bra{a}_1\bra{b}_2 + \bra{b}_1\bra{a}_2}{2} \frac{\ket{a}_1 \ket{b}_2 - \ket{b}_1 \ket{a}_2}{2} \\ & = - \frac{1}{4} (\underbrace{\braket{a}{a}_1}_1 \underbrace{\braket{b}{b}_2}_1 - \braket{a}{b}_1 \braket{b}{a}_2 + \braket{b}{a}_1 \braket{a}{b}_2 - \underbrace{\braket{b}{b}_1}_1 \underbrace{\braket{a}{a}_2}_1) \\ & = - \frac{1}{4} (- \braket{a}{b}_1 \braket{b}{a}_2 + \braket{b}{a}_1 \braket{a}{b}_2) \\ & = \frac{1}{4} (- \braket{a}{b}_2 \braket{b}{a}_1 + \braket{b}{a}_2 \braket{a}{b}_1 ) ~,
    \end{aligned}
    \end{equation*}
    which means that $\braket{\psi_S}{\psi_A} = - \braket{\psi_S}{\psi_A}$. Therefore, the only solution is $\braket{\psi_S}{\psi_A} = 0$.
    \end{proof}
    
    Notice that Pauli's exclusion principle is encoded into the antysymmetric part, because if $a = b$ we have $\ket{\psi_A} = 0$.

    The decomposition is equivalent to define two orthogonal projectors: the symmetriser 
    \begin{equation*}
        \hat S \colon \mathcal H \rightarrow \mathcal H_S
    \end{equation*}
    and the antisymmetriser 
    \begin{equation*}
        \hat A \colon \mathcal H \rightarrow \mathcal H_A ~,
    \end{equation*}
    such that they satisfy the properties 
    \begin{equation}\label{proj}
        \hat S^\dagger = \hat S~, \quad \hat A^\dagger = \hat A~, \quad \hat S^2 = \hat S~, \quad \hat A^2 = \hat A~, \quad \hat S \hat A = \hat A \hat S = 0 ~.
    \end{equation}

\subsection{$N$ particles}

    Generalising for $N$ particles, if they are distinguishable, the total Hilbert space is 
    \begin{equation*}
        \mathcal H_{tot} = \mathcal H \otimes \ldots \mathcal H
    \end{equation*}
    and a state is $\ket{\psi} = \ket{a_1}_1 \ldots \ket{a_N}_N = \ket{1, \ldots N}$ where $\ket{a_j} \in \mathcal H$. 

    However, if the particle are indistinguishable, similarly to the $2$ particles case, we can define the symmetriser
    \begin{equation*}
        \hat S \colon \ket{\psi} \mapsto \frac{1}{N!} \sum_{P \in P_N} \ket{P(1), \ldots P(N)}
    \end{equation*}
    and the antisymmetriser
    \begin{equation*}
        \hat A \colon \ket{\psi} \mapsto \frac{1}{N!} \sum_{P \in P_N} sgn(P) \ket{P(1), \ldots P(N)} ~,
    \end{equation*}
    where $P(1, \ldots N) \mapsto (P(1), \ldots P(N))$. 
    They satisfy the orthogonal projector properties~\eqref{proj}. Notice that for $N > 2$ particles, the total Hilbert space is $\mathcal H_{tot} = \mathcal H_S \otimes \mathcal H_A \otimes \mathcal H'$, where bosons work only in $\mathcal H_S$, fermions work only in $\mathcal H_A$ and $\mathcal H'$ is not physical.

    \begin{example}
        For $N=3$, we can have $\psi_S \in mathcal H_S$
        \begin{equation*}
            \psi_S = \hat S \psi = \psi(1,2,3) + \psi(1,3,2) + \psi(2,1,3) + \psi(2,3,1) + \psi(3,1,2) + \psi(3,2,1)
        \end{equation*}
        and $\psi_A \in mathcal H_A$
        \begin{equation*}
            \psi_A = \hat A \psi = \psi(1,2,3) - \psi(1,3,2) - \psi(2,1,3) + \psi(2,3,1) + \psi(3,1,2) - \psi(3,2,1) ~.
        \end{equation*}
        However, we can also have $\psi' \in \mathcal H'$ such that
        \begin{equation*}
            \psi' = \psi(1,2,3) + \psi(1,3,2) -  \psi(2,1,3) - \psi(2,3,1) + \psi(3,1,2) + \psi(3,2,1) ~.
        \end{equation*}
    \end{example}
    
    For $N$ distinguishable particle, consider an orthonormal basis for the total Hilbert space
    \begin{equation*}
        \{u_{\alpha_1}(x_1) \ldots u_{\alpha_N}(x_N)\}_{\alpha_1, \ldots \alpha_N=0}^\infty ~,
    \end{equation*}
    where $\{u_{\alpha_K} (x_k)\}_{\alpha_k = 1}^\infty$ is an orthonormal basis for a single Hilbert space $\mathcal H_1$. Notice that they are labelled by the ordered set $(\alpha_1, \ldots \alpha_N)$ and we are specifying which particle is in which states. 

    In order to construct an orthonormal basis for $\mathcal H_A$ and $\mathcal H_S$ for $N$ indistinguishable particles, we project the distinguishable orthonormal basis respectively with the antisymmetriser and the symmetriser
    \begin{equation*}
        \ket{n_1, \ldots n_j, \ldots} = C \begin{cases} \hat S \\ \hat A \end{cases} ~ u_{\alpha_1}(x_1) \ldots u_{\alpha_N}(x_N) ~.
    \end{equation*}
    By the properties of the projectors, they are orthonormal but they are not normalised. Therefore, we need to choose a normalisation constant
    \begin{equation*}
        C = \begin{cases}
            \sqrt{\frac{N!}{n_1! \ldots n_k! \ldots}} & \mathcal H_S \\
            \sqrt{N!} & \mathcal H_A \\
        \end{cases} ~.
    \end{equation*}

    On the contrary for the distinguishable case, now we lose information, because we know only how many particle are in each state and not anymore which is in which state. We label the states with $n_1, \ldots n_k, \dots$ with $j=1, \ldots \infty$, which are the occupation number. For bosons, we have $n_k = 0, 1, \ldots, \infty$, whereas for fermions, we have $n_k = 0, 1$. For both cases, there is the constrain $N = \sum_k n_k$, which is an infinite sum but mostly are zero occupied. Moreover, given the set $\alpha_k$, we uniquely determine the occupation number $n_k$, but given the occupation number $n_k$, we use the symmetric or antisymmetric property to uniquely determine the state, because it is in $1-1$ correspondence to the set $n_k$. 

    Nonetheless, there is another way to describe fermionic or bosonic quantum space in a intrinsic way, called the second quantisation because we make a further quantisation, promoting fields to operators.

\chapter{Second quantisation} 

\section{Bosonic case}
   
    We define bosonic creation and annihilation operators such that they satisfies the properties 
    \begin{equation}\label{bos}
        [\hat a, \hat a^\dagger]_- = \hat a \hat a^\dagger - \hat a^\dagger \hat a = \mathbb I~.
    \end{equation}
    Furthermore, the number operator $\hat N = \hat a^\dagger \hat a$ such that 
    \begin{equation*}
        [\hat N, \hat a] = - \hat a~, \quad [\hat N, \hat a^\dagger] = \hat a^\dagger ~.
    \end{equation*} 

    By analogy with the harmonic oscillator, the ground state is the vacuum 
    \begin{equation*}
        \hat a \ket{0} = 0 ~,
    \end{equation*}
    and a generic state is defined by the ladder operators
    \begin{equation*}
        \ket{\psi} = \frac{1}{\sqrt{n!}} (\hat a^\dagger)^N \ket{0} ~.
    \end{equation*}

\section{Fermionic case}

    We define fermionic creation and annihilation operators such that they satisfies the properties 
    \begin{equation}\label{ferm}
        [\hat a, \hat a^\dagger]_+ = \hat a \hat a^\dagger + \hat a^\dagger \hat a = \mathbb I ~.
    \end{equation}
    Furthermore, the number operator $\hat N = \hat a^\dagger \hat a$ such that 
    \begin{equation*}
        [\hat N, \hat a] = - \hat a~, \quad [\hat N, \hat a^\dagger] = \hat a^\dagger ~.
    \end{equation*} 

    The properties can be obtained from the Pauli matrices 
    \begin{equation*}
        \sigma_\pm = \sigma_1 \pm i \sigma_2 ~,
    \end{equation*}
    such that 
    \begin{equation*}
        (\sigma_+)^\dagger = \sigma_- ~, \quad (\sigma_-)^\dagger = \sigma_+ ~, \quad (\sigma_+)^2 = (\sigma_-)^2 = 0 ~, \quad [\sigma_-, \sigma_+]_+ = \mathbb I ~.
    \end{equation*}

    By analogy with the harmonic oscillator, the ground state is the vacuum 
    \begin{equation*}
        \hat a \ket{0} = 0 ~,
    \end{equation*}
    and a generic state is defined by the ladder operators
    \begin{equation*}
        \ket{\psi} = \frac{1}{\sqrt{n!}} (\hat a^\dagger)^N \ket{0} ~.
    \end{equation*}

    However, the anticommutator relation ensures the validity of the Pauli's exclusion principle. In fact, we have 
    \begin{equation*}
        a^2 = (\hat a^\dagger)^2 = 0 ~.
    \end{equation*}

\section{Fock space}

    Consider a single particle Hilbert space $\mathcal H$ with an orthonormal basis $\{\ket{e_n}\}_{n=1}^\infty$. To each $\ket{e_n}$, we associate an annihilation and a creation operators 
    \begin{equation*}
        \ket{e_n} \mapsto \{\hat a_n, \hat a_n^\dagger \}_{n=1}^\infty ~,
    \end{equation*}
    such that they satisfy
    \begin{equation*}
        [\hat a_n, \hat a_m]_\pm = [\hat a_n^\dagger, \hat a_m^\dagger]_\pm = 0 ~, \quad [\hat a_n, \hat a_m^\dagger]_\pm = \delta_{nm} ~,
    \end{equation*}
    where the minus sign correponds to the commutator (bosons)~\eqref{bos} and the plus sign to the anticommutator (fermions)~\eqref{fer}. 

    The normalised vacuum state, which describes a no particle state, is defined by the annihilation of every annihilation operator
    \begin{equation*}
        \hat a_n \ket{0} = 0 \quad \forall n~.
    \end{equation*}
    It generates a subspace of dimension $1$ 
    \begin{equation}\label{vac}
        \mathcal H^{(0)}_{S/A} = \{\lambda \ket{0} \colon \lambda \in \mathbb C \} ~.
    \end{equation}

    Now, we define the one-particle state. For each $\ket{e_n}$, we associate a number operator $\hat n_k = \hat a_k^\dagger \hat a_k$ such that 
    \begin{equation*}
        \hat n_k \hat a_k^\dagger \ket{0} = 1 \hat a_k^\dagger \ket{0} ~, \quad \hat n_{k'} \hat a_k^\dagger \ket{0} = 0 \quad k' \neq k ~.
    \end{equation*}
    For a $n$ particle state, we have 
    \begin{equation*}
        \hat a_k^\dagger \ket{0} = \ket{n_1=0, \ldots n_k=1, \ldots n_N=0} = \ket{e_k} ~.
    \end{equation*}

    However, for 
    \begin{equation*}
        \hat a_{k_1}^\dagger \hat a_{k_2}^\dagger \ket{0} = \ket{e_{k_1}} \ket{e_{k_2}} 
    \end{equation*}
    we have for fermions, if $k_1 = k_2 = k$
    \begin{equation*}
    (\hat a^\dagger_k)^2 \ket{0} = 0 ~,
    \end{equation*}
    whereas for bosons 
    \begin{equation*}
        (\hat a^\dagger_k)^2 \ket{0} \neq 0 ~.
    \end{equation*}
    Furthermore, if $k_1 \neq  k_2$, we have for fermions
    \begin{equation*}
        \hat a^\dagger_{k_1} \hat a^\dagger_{k_2} \ket{0} = - \hat a^\dagger_{k_2} \hat a^\dagger_{k_1} \ket{0} ~,
    \end{equation*}
    whereas for bosons 
    \begin{equation*}
        \hat a^\dagger_{k_1} \hat a^\dagger_{k_2} \ket{0} = \hat a^\dagger_{k_2} \hat a^\dagger_{k_1} \ket{0} ~.
    \end{equation*}

    There is a $1-1$ correspondence between the orthonormal basis  $\{\ket{e_n}\}_{n=1}^\infty$ of $\mathcal H$ and the orthonormal basis $\{\hat a_k \ket{0}\}_{k=1}^\infty$ of $\mathcal H_{S/A}$. Hence for $N$ particles, we have 
    \begin{equation*}
        \mathcal H_{S/A}^{(N)} = \{\ket{n_1, \ldots n_k, \ldots} = \frac{1}{\sqrt{ \prod_j n_j}} (\hat a_1^\dagger)^{n_1} \ldots (\hat a_k^\dagger)^{n_k} \ldots \ket{0} \} ~.
    \end{equation*} 

    If $N$ is not fixed, like the passage from canonical to grancanonicl ensemble, the total Fock space is 
    \begin{equation*}
        \mathcal F = \bigoplus_{N=0}^\infty \mathcal H^{(N)}_{S/A} ~.
    \end{equation*} 

    It satisfies the following properties 
    \begin{enumerate}
        \item orthonormality, i.e. 
            \begin{equation*}
                \braket{{n'}_1, \ldots {n'}_k, \ldots}{n_1, \ldots n_k, \ldots} = \delta_{{n'}_1, n_1} \ldots \delta_{{n'}_k, n_k} \ldots  ~,
            \end{equation*}
        \item annihilation $\hat a_k \colon \mathcal H^{(N)}_{S/A} \rightarrow \mathcal H^{(N-1)}_{S/A}$, i.e.
            \begin{equation*}
                \hat a_k \ket{n_1, \ldots n_k, \ldots} = \eta_k \sqrt{n_k} \ket{n_1, \ldots (n_k - 1), \ldots} ~,
            \end{equation*}
            where for bosons $\eta_k = 1$ and for fermions $\eta_k = (-1)^{\sum_{j < k} n_j}$,
        \item creation $\hat a_k^\dagger \colon \mathcal H^{(N)}_{S/A} \rightarrow \mathcal H^{(N+1)}_{S/A}$, i.e. for bosons
            \begin{equation*}
                \hat a^\dagger_k \ket{n_1, \ldots n_k, \ldots} = \sqrt{n_k + 1} \ket{n_1, \ldots (n_k + 1), \ldots} ~,
            \end{equation*}
            and for fermions
            \begin{equation*}
                \hat a^\dagger_k \ket{n_1, \ldots n_k, \ldots} = \eta_k \sqrt{1 - n_k} \ket{n_1, \ldots (n_k + 1), \ldots} ~,
            \end{equation*}
        \item number operator $\hat n_k = \hat a_k^\dagger \hat a_k$ such that 
            \begin{equation*}
                \hat n_k \ket{n_1, \ldots n_k, \ldots} = n_k \ket{n_1, \ldots n_k, \ldots}
            \end{equation*}
        and the total number operator $\hat N = \sum_k \hat n_k \sum_k \hat a^\dagger_k \hat a_k$ such that 
        \begin{equation*}
            \hat N \ket{n_1, \ldots n_k, \ldots} = \Big (\sum_k n_k \Big ) \ket{n_1, \ldots n_k, \ldots} ~.
        \end{equation*}
    \end{enumerate}

\section{Field operators} 

    In the first quantisation, we quantise observables to operators, while, in the second quantisation, we quantise fields to operators. Now, a generic particle state is represented by $\ket{f} = \sum_k f_k \ket{e_k} \in \mathcal H$, which is equivalent to $sum_k f_k \hat a_k^\dagger \ket{0}$. Hence, we define the field operators
    \begin{equation*}
        \hat \psi^\dagger (f) = \sum_k f_k \hat a^\dagger_k ~, \quad \hat \psi (f) = \sum_k f_k^* \hat a_k ~,
    \end{equation*}
    in order to get a state $\hat \psi (f) \ket{0}$. The related commutator relations become
    \begin{equation*}
        [\hat \psi (f), \hat \psi^\dagger (g)]_\pm = \braket{f}{g}\mathbb I ~.
    \end{equation*}
    \begin{proof}
        In fact,
        \begin{equation*}
            [\hat \psi (f), \hat \psi^\dagger (g)]_\pm = [\sum_k f^*_k \hat a_k, \sum_m g_m \hat a^\dagger]_\pm = \sum_k \sum_m f^*_k g_m \underbrace{[\hat a_k, \hat a^\dagger_m]}_{\delta_{km} \mathbb I} = \sum_k \sum_m f^*_k g_m \underbrace{\delta_{km}}_{k= m} \mathbb I = \sum_k f^*_k g_k \mathbb I = \braket{f}{g} \mathbb I ~.
        \end{equation*}
        where we have used $\ket{f} \sum_k f_k \ket{e_k}$, $\ket{g} = \sum_m g_m \ket{e_m}$ and $\braket{f}{g} = \sum_k \sum_m f^*_k g_m \underbrace{\braket{e_k}{e_m}}_{\delta_{km}} = \sum_k f^*_k g_k$.
    \end{proof}

    Consider a single particle state in $\mathcal H = L^2(\mathbb R^d) \ni \psi(x)$ with an orthonormal basis $u_k(x)$ such that to each ket there are ladder operators $\hat a_k$ and $\hat a_k^\dagger$. Hence $L^2(\mathbb R^d) \ni f(x) = \sum_k f_k u_k(x)$ and we define field operators
    \begin{equation*}
        \hat \psi(x) = \sum_k u_k^* (x) \hat a_k ~, \quad \hat \psi^\dagger (x) = \sum_k u_k (x) \hat a_k^\dagger ~,
    \end{equation*}
    which is alinear superposition of annihilation and creation operators. Actually, it is called an operator-valued function because its output is an operator. In fact 
    \begin{equation*}
        \int_{\mathbb R^d} d^d x ~ \psi^\dagger (x) \sum_k u_k^* (x) \hat a_k^\dagger = \sum_k \hat a_k^\dagger \int_{\mathbb R^d} d^d x ~ u^*_k(x) f(x) = \sum_k \hat a_k^\dagger f_k~,
    \end{equation*}
    where we have exchanged sum and integral because they are convergent. 

    The commutation relations are 
    \begin{equation*}
        [\psi(x), \psi^\dagger (y)] = \mathbb I \delta (x - y) ~.
    \end{equation*}
    \begin{proof}
        In fact,
        \begin{equation*}
            [\hat \psi (f), \hat \psi^\dagger (g)]_\pm = [\int d^d x ~ f^* (x) \hat \psi(x), \int d^d y ~ g(y) \hat \psi^\dagger (y)]_\pm = \int d^d x \int d^d y ~ f^*(x) g(y) [\psi(x), \psi^\dagger (y)]  ~,
        \end{equation*}
        which must be equal to 
        \begin{equation*}
            \braket{f}{g} = \int d^d x ~ f^* (x) g(x) ~.
        \end{equation*}
        Hence 
        \begin{equation*}
            [\psi(x), \psi^\dagger (y)] = \mathbb I \delta (x - y) ~.
        \end{equation*}
    \end{proof}

    For instance, a plane wave $u(x) = \exp (i \mathbf k \cdot \mathbf x) $ and $\hat \psi(x) = \sum_k \hat a_k^\dagger \exp(i \mathbf k \cdot \mathbf x)$.

    Notice that field operators are basis independent

\section{Operators}

    Consider a Fock space $\mathcal F = \bigoplus_{N=0}^\infty \mathcal H^{(N)}_{B/F}$ with orthonormal basis $\ket{n_1, \ldots n_k, \ldots} = \frac{1}{\sqrt{\prod_j n_j !}} (\hat a^\dagger_1)^{n_1} \ldots (\hat a_k^\dagger)^{n_k} \ldots \ket{0}$, which is in $1-1$ correspondence to the orthonormal basis $\psi_{n_1 \ldots n_k \ldots} (x_1, \ldots x_k, \ldots) = c_N \begin{bmatrix} \hat S \\ \hat A \\ \end{bmatrix} u_{\alpha_1} (x_1) \ldots u_{\alpha_k} (x_k) \ldots$, where $hat S$ is the symmetriser and $\hat A$ is the antisymmetriser.

    We define a one-body operator, associated to a system in which all the particles are the same, as 
    \begin{equation*}
        \hat O^{(1)} = \sum_{j=1}^{N} \hat O(\hat p_j, \hat x_j) ~.
    \end{equation*}
    Since it is self-adjoint, it exists an orthonormal basis of eigenvalues $\{u_\alpha (x)\}$, such that 
    \begin{equation*}
        \hat O(\hat p, \hat x) u_\alpha (x) = \epsilon_\alpha u_\alpha (x) ~.
    \end{equation*}

    Since 
    \begin{equation*}
    \begin{aligned}
        \hat O^{(1)} \psi_{n_1 \ldots n_k \ldots} (x_1, \ldots x_k, \ldots) & = \Big ( \sum_{j=1}^{\infty} \hat O(\hat p_j, \hat x_j) \Big) \psi_{n_1 \ldots n_k \ldots} (x_1, \ldots x_k, \ldots) \\ & = \Big ( \sum_{j=1}^{\infty} \hat O(\hat p_j, \hat x_j) \Big) c_N \begin{bmatrix} \hat S \\ \hat A \\ \end{bmatrix} u_{\alpha_1} (x_1) \ldots u_{\alpha_k} (x_k) \ldots \\ & = c_N \begin{bmatrix} \hat S \\ \hat A \\ \end{bmatrix} \Big ( \sum_{j=1}^{\infty} \hat O(\hat p_j, \hat x_j) u_{\alpha_1} (x_1) \ldots u_{\alpha_k} (x_k) \ldots \Big) \\ & = c_N \begin{bmatrix} \hat S \\ \hat A \\ \end{bmatrix} \Big ( \sum_{j=1}^{\infty}  u_{\alpha_1} (x_1) \ldots \underbrace{\hat O(\hat p_j, \hat x_j) u_{\alpha_j} (x_j)}_{\epsilon_{\alpha_j} u_{\alpha_j} (x_j) } \ldots \Big) \\ & = \Big (\sum_{j=1}^{\infty} \epsilon_j n_j \Big ) \psi_{n_1 \ldots n_k \ldots} (x_1, \ldots x_k, \ldots) ~.
    \end{aligned}
    \end{equation*}

    For the Fock space, we have 
    \begin{equation*}
        \hat O^{(1)}_F = \sum_{j=1}^{\infty} \epsilon_j \hat n_j = \sum_{j=1}^{\infty} \epsilon_j \hat a_j^\dagger \hat a_j ~,
    \end{equation*}
    where 
    \begin{equation*}
        \epsilon_j = \bra{u_j (x)} \hat O (\hat p_j, \hat x_j) \ket{u_j(x)} ~.
    \end{equation*}
    Hence 
    \begin{equation*}
        \hat O^{(1)}_F = \sum_{j=1}^{\infty} \bra{u_j (x)} \hat O (\hat p_j, \hat x_j) \ket{u_j(x)} \hat a_j^\dagger \hat a_j ~.
    \end{equation*}

    Since it is dependent of the basis, because we choose the eigenbasis, we choose a different arbitrary basis 
    \begin{equation*}
        \psi^\dagger (x) = \sum_k u_k (x) \hat a^\dagger_k = \sum_m v_m (x) b^\dagger_m ~,
    \end{equation*}
    and we define the one-body operator
    \begin{equation}\label{basind}
        \hat O^{(1)}_F = \int d^d x ~ \hat \varphi^\dagger (x) \hat O (\hat p, \hat x) \hat \varphi (x) ~,
    \end{equation}
    which this time is basis independent.
    \begin{proof}
        In fact 
        \begin{equation*}
        \begin{aligned}
            \int d^d x ~ \hat \varphi^\dagger (x) \hat O (\hat p, \hat x) \hat \varphi (x) & = \int d^d x ~ \Big ( \sum_k u_k(x) \hat a^\dagger (x) \Big ) \hat O (\hat p, \hat x) \Big ( \sum_m u_m^* (x) \hat a_m (x) \Big ) \\ & = \sum_k \sum_m \hat a_k^\dagger \hat a_m \int d^d x ~ u_k (x) \underbrace{\hat O(\hat p, \hat x) u^*_m (x)}_{\epsilon_m u^*_m (x)} \\ & = \sum_k \sum_m \hat a_k^\dagger \hat a_m \epsilon_m \underbrace{\int d^d x ~ u_k (x) u^*_m (x)}_{\delta_{km}} \\ & = \sum_k \sum_m \hat a_k^\dagger \hat a_m \epsilon_m \underbrace{\delta_{km}}_{k = m} \\ & = \sum_k\hat a_k^\dagger \hat a_k \epsilon_k = \hat O^{(1)}_F ~.
        \end{aligned}
        \end{equation*}
    \end{proof}
    It can be written as 
    \begin{equation*}
        \hat O^{(1)}_F = \sum_k \sum_m t_{km} \hat b_k^\dagger \hat h_m ~,
    \end{equation*}
    where the transition amplitude is
    \begin{equation*}
        t_{km} = \bra{v_k} \hat O (\hat p, \hat x) \ket{v_m} ~.
    \end{equation*}

    To summarise, the onebody operator is 
    \begin{equation*}
        \hat O^{(1)}_F = \begin{cases}
            \sum_{m m'} t_{mm'} \hat b^\dagger_m \hat b_m & \textnormal{arbitrary basis} \\
            \sum_k \epsilon_k \hat a^\dagger_k \hat a_k & \textnormal{eigenbasis} \\
        \end{cases} ~.
    \end{equation*}

\section{Examples} 

    The density operator of a single particle $j$ is 
    \begin{equation*}
        \hat \rho_j = \delta (x - x_j)
    \end{equation*}
    and the corresponding field operator is 
    \begin{equation*}
        \hat \varphi (x_j) = \int d^d x  \psi (x) \delta (x - x_j) ~.
    \end{equation*}

    The onebody operator is 
    \begin{equation*}
        \hat \rho^{(1)} = \sum_{j=1}^{N} \delta (x - x_j) ~,
    \end{equation*}
    which in the basis independent definition~\eqref{basind} on the Fock space 
    \begin{equation*}
        \hat \rho_F = \int d^d y \hat \psi^\dagger (y) \delta (x - y) \hat \psi (y) = \hat \psi^\dagger \hat \psi = \sum_{kk'} u_k^* (x) u_{k'} (x) \hat a^\dagger_k \hat a_{k'} ~.
    \end{equation*}

    The number of particle operator is 
    \begin{equation*}
        \hat N = \int d^d x \hat \rho^{(1)}_F (x) = \int d^d x \sum_{kk'} u^*_k (x) u_{k'} (x) \hat a^\dagger_k \hat a_{k'} = \sum_{kk'} \hat a^\dagger_k \hat a_{k'} \underbrace{\int d^d x u^*_k (x) u_{k'} (x)}_{\delta_{kk'}} = \sum_{kk'} \hat a^\dagger_k \hat a_{k'} \underbrace{\delta_{kk'}}_{k = k'} = \sum_k \hat a^\dagger_k \hat a_k = \sum_k \hat n_k ~,
    \end{equation*}
    which is consistent with the definition of $\rho$ since it can be seen as a density of particle whose intergral is indeed the number of particles.

\subsection{Free non-relativistic $3$-dimensional particles} 

    Consider the hamiltonian of a single particle described by the wave function $\psi (x) \in L^2 (\mathbb R^d)$ 
    \begin{equation*}
        \hat H_1 = \frac{\hbar^2 \hat p^2}{2m} = - \frac{\hbar^2}{2m} \nabla_x^2 ~.
    \end{equation*}
    The onebody operator for $N$ particles is 
    \begin{equation*}
        \hat H = \sum_{j = 1}^{N} \frac{\hbar^2 hat p_j^2}{2m} = - \sum_{j = 1}^{N} \frac{\hbar^2}{2m} \nabla^2_{x_j} ~.
    \end{equation*}
    On the Fock space, it becomes 
    \begin{equation*}
        H = \sum_k \epsilon_k \hat a_k^\dagger \hat a_k ~,
    \end{equation*}
    where 
    \begin{equation*}
        \hat H_1 u_k (x) = - \frac{\hbar^2}{2m} u_k (x) = \epsilon_k u_k (x) ~.
    \end{equation*}
    However, wave plane solutions do not belong in $u_k(x) \sim \exp(i \mathbf k \cdot \mathbf x) \notin L^2 (\mathbb R^d)$, because they are not normalisable. The trick is to go into a finite volume $V$ and consider the space $L^2(V)$. The simple example is the particle in a cube of length $L$ describer by the coordinates $(x,y,z) \in [0, L]$. The Schoredinger's equation becomes 
    \begin{equation*}
        - \frac{\hbar^2}{2m} \nabla_x^2 u_k (x,y,z) = \epsilon_k u_k (x,y,z) ~.
    \end{equation*}
    Now, we do not choose the Dirichlet or the Neumann boundary condition, but we choose the periodic boundary conditions 
    \begin{equation*}
        \begin{cases}
            u(x=0, y, z) = u(x = L, y, z) \\
            u(x, y=0, z) = u(x, y=L, z) \\
            u(x, y, z=0) = u(x, y, z=L) \\
        \end{cases} ~,
    \end{equation*}
    which trasforms the cube into a $3$-torus.

    The ansatz solution is 
    \begin{equation*}
        u_\alpha (\mathbf x) = c \exp(i \mathbf k \cdot \mathbf x) ~,
    \end{equation*}
    where $c$ is a normalisation constant and 
    \begin{equation*}
        \nabla_2 u_\alpha (\mathbf x) = - (k_x^2 + k_y^2 + k_z^2) u_\alpha (\mathbf x) = \epsilon_{\mathbf k} = - k^2 ~.
    \end{equation*}
    Imposing the periodic boundary conditions, we obtain 
    \begin{equation*}
        u_{\mathbf k} (0,y,z) = \cancel{c} \exp(i \cancel{(k_y y + k_z z)}) = u_{\mathbf k} (L,y,z) = \cancel{c} \exp(i (k_x L + \cancel{k_y y + k_z z})) ~,
    \end{equation*}
    hence
    \begin{equation*}
        \exp(i k_x L) = 0 
    \end{equation*}
    and 
    \begin{equation*}
        k_x = \frac{2 \pi}{L} n_x ~,
    \end{equation*}
    where $n \in \mathbb Z$ is an integer number. Simiarly for $y$ and $z$, we have 
    \begin{equation*}
        \mathbf k = (k_x, k_y, k_z) = \frac{2\pi}{L} \mathbf n = \frac{2\pi}{L} (n_x, n_y, n_z) 
    \end{equation*}
    where $n_x, n_y, n_z \in \mathbb Z$. Finally, the energy eigenvalues are 
    \begin{equation*}
        \epsilon_{n_x, n_y, n_z} = - \frac{4\pi^2}{L^2} (n_x^2 + n_y^2 + n_z^2) 
    \end{equation*}
    and the eigenstates are 
    \begin{equation*}
        u_{n_x, n_y, n_z} = c \exp(i \frac{2\pi}{L} (n_x x + n_y y + n_z z)) \in L^2(V) ~.
    \end{equation*}
    The normalisation constant is 
    \begin{equation*}
        C = \frac{1}{\sqrt{V}} ~.
    \end{equation*}
    In fact 
    \begin{equation*}
        1 = ||u_{n_x, n_y, n_z} ||^2 = \int_V dx ~ dy ~ dz ~ |c|^2 |\exp(i \mathbf k \cdot \mathbf x)|^2 = |c|^2 V ~.
    \end{equation*}
    Hence, the onebody operator is 
    \begin{equation*}
        \hat O^{(1)} = \sum_{j=1}^{N} \frac{\hat p^2_j}{2m} = - \sum_{j=1}^{N} \frac{\hbar^2}{2m} \nabla^2_{\mathbf x_j} ~,
    \end{equation*}
    and choosing the orthonormal basis of wavefunctions, we have in the Fock space 
    \begin{equation*}
        \hat O_F = \sum_{\mathbf k} \epsilon_{\mathbf k} \hat a^\dagger_{\mathbf k} \hat a_{\mathbf k} ~,
    \end{equation*}
    where $\mathbf k = \frac{2\pi}{L} (n_x, n_y, n_z)$ and $\epsilon_{\mathbf k} = \frac{\hbar^2}{2m} k^2$.

\subsection{Interaction potential}

    Now, consider a different operator than the onebody one: the two particles operatior, used to describe interaction potential 
    \begin{equation*}
        \hat O^{(2)} = \sum_{i < j} V(x_i, x_j) = \frac{1}{2} \int dx \int dy V(x,y) \hat \psi^\dagger (x) \hat \psi^\dagger (y) \psi(y) \psi (x) ~,
    \end{equation*}
    or 
    \begin{equation*}
        \hat O^{(2)} = \frac{1}{2} \sum_{ijkl} V_{ijkl} \hat a_i^\dagger \hat a_j^\dagger \hat a_k \hat a_l ~,
    \end{equation*}
    where the first expression is basis-independent, while in the last one it is in the eigenbasis. 
    \begin{proof}
        Maybe in the future.
    \end{proof}
